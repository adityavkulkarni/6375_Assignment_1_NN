Activation,Gradient,Optimizer,Learning Rate,Epochs,Loss,Test Accuracy,Time
sigmoid,batch,adagrad,0.001,50,0.93385214,0.03239291,20.419281
sigmoid,batch,momentum,0.005,100,0.906614786,0.045357063,32.773245
sigmoid,batch,none,0.05,100,0.926070039,0.034425707,29.766018
tanh,batch,momentum,0.005,100,0.961089494,0.019538431,31.434853
tanh,batch,none,0.05,100,0.937743191,0.027540228,29.563148
relu,batch,momentum,0.008,100,0.937743191,0.028798177,31.022458
relu,batch,none,0.05,100,0.941634241,0.024835799,28.326977
tanh,batch,adagrad,0.0001,100,0.964980545,0.01686924,40.266213
relu,batch,adagrad,0.00005,50,0.891050584,0.048975224,19.258045